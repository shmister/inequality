{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy import interpolate\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import __version__\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx], idx\n",
    "\n",
    "def cum_wgts_vals(values, values_weights=None, sort_top=False):\n",
    "\n",
    "    if values_weights is None:\n",
    "        values_weights = np.ones(len(values))*1/len(values)\n",
    "\n",
    "    df = pd.DataFrame({'values': values, 'weights': values_weights})\n",
    "    if sort_top:\n",
    "        df = df.sort_values('values', ascending= False)\n",
    "    else:\n",
    "        df = df.sort_values('values', ascending= True)\n",
    "    df['temp'] = df['weights']*df['values']\n",
    "\n",
    "    cum_weights = np.cumsum(df['weights'])/np.sum(df['weights']) # cumulative probability distribution\n",
    "    cum_values = np.cumsum(df['temp'])/np.sum(df['temp']) # cumulative ownership shares\n",
    "\n",
    "    return list(cum_weights), list(cum_values)\n",
    "\n",
    "\n",
    "def dist_points(vals_distribution, btm_range=None, top_range=None, weights=None):\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(vals_distribution))*1/len(vals_distribution)\n",
    "    \n",
    "    cum_weights_top, cum_values_top = cum_wgts_vals(vals_distribution, weights, sort_top= True)\n",
    "    cum_weights_btm, cum_values_btm = cum_wgts_vals(vals_distribution, weights, sort_top= False)\n",
    "    \n",
    "    dist_points_array = []\n",
    "    for i in np.arange(0.01, 1.0, 0.01):\n",
    "        _, top_idx = find_nearest(cum_weights_top, i)\n",
    "        _, btm_idx = find_nearest(cum_weights_btm, i)\n",
    "        top_wealth = cum_values_top[top_idx]\n",
    "        btm_wealth = cum_values_btm[btm_idx]\n",
    "        \n",
    "        dist_points_array.append([round(i, 2), btm_wealth, top_wealth])\n",
    "    \n",
    "    dist_points_df = pd.DataFrame(dist_points_array, columns=['percent', 'btm_wealth', 'top_wealth'])  \n",
    "    dist_points_melted = pd.melt(dist_points_df, id_vars=['percent'], value_vars=['btm_wealth', 'top_wealth'])\n",
    "    \n",
    "    if btm_range is None:\n",
    "        btm_range = [0.1, 0.2, 0.4]\n",
    "    if top_range is None:\n",
    "        top_range = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.6]\n",
    "    \n",
    "    dist_selected_top = dist_points_melted[(dist_points_melted['variable']=='top_wealth') & (dist_points_melted['percent'].isin(top_range))]\n",
    "    dist_selected_btm = dist_points_melted[(dist_points_melted['variable']=='btm_wealth') & (dist_points_melted['percent'].isin(btm_range))]\n",
    "    \n",
    "    return pd.concat([dist_selected_top, dist_selected_btm.sort_values('percent', ascending=False)])\n",
    "\n",
    "def gini(income, weights=None):\n",
    "    \n",
    "    if weights is None:\n",
    "        weights = np.ones(len(income))*1/len(income)\n",
    "\n",
    "    df = pd.DataFrame({'income': income, 'weights': weights}).sort_values('income', ascending= True)\n",
    "    \n",
    "    x = df['income']\n",
    "    f_x = df['weights'] / df['weights'].sum()\n",
    "    F_x = f_x.cumsum()\n",
    "    mu = np.sum(x * f_x)\n",
    "    cov = np.cov(x, F_x, rowvar=False, aweights=f_x)[0,1]\n",
    "    g = 2 * cov / mu\n",
    "    return g\n",
    "\n",
    "def metrics(name, income, weights=None):\n",
    "    dist_df = dist_points(vals_distribution=income, weights=weights)\n",
    "    gini_df = pd.DataFrame({'percent': [0.00], 'variable': ['gini'], 'value': [gini(income, weights)]})\n",
    "    metrics_df = pd.concat([dist_df, gini_df])\n",
    "    metrics_df.columns = ['percent', name ,'var']\n",
    "    return metrics_df\n",
    "\n",
    "\n",
    "def lorenz_points(vals_distribution, weights=None):\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(vals_distribution))*1/len(vals_distribution)\n",
    "\n",
    "    df = pd.DataFrame({'values': vals_distribution, 'weights': weights}).sort_values('values', ascending= True)\n",
    "    df['temp'] = df['weights']*df['values']\n",
    "\n",
    "    cum_dist = np.cumsum(df['weights'])/np.sum(df['weights']) # cumulative probability distribution\n",
    "    cum_data = np.cumsum(df['temp'])/np.sum(df['temp']) # cumulative ownership shares\n",
    "\n",
    "    lorenz_x = np.linspace(0.0,1.0,100)\n",
    "    lorenz_y = interp1d(cum_dist,cum_data,bounds_error=False,assume_sorted=True)(lorenz_x)\n",
    "\n",
    "    return lorenz_x, lorenz_y, cum_dist, cum_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_immediate_subdirectories(a_dir):\n",
    "    return [name for name in os.listdir(a_dir)\n",
    "            if os.path.isdir(os.path.join(a_dir, name))]\n",
    "\n",
    "def get_param_values(params_file):\n",
    "    shares, gammas = None, None\n",
    "    with open(params_file) as fp:\n",
    "        for cnt, line in enumerate(fp):\n",
    "            if 'equal_shares = ' in line and '#' not in line:\n",
    "                shares = line\n",
    "            elif 'gammaL, gammaM, gammaH' in line:\n",
    "                gammas = line[0:40]\n",
    "    return gammas + \"\\n\" + shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_folder = '/Users/mitya/Desktop/inequality/codes/gitcode/inequality/output/'\n",
    "versions = [wd_folder + v for v in get_immediate_subdirectories(wd_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df = pd.read_pickle('/Users/mitya/Desktop/inequality/codes/gitcode/inequality/data/scf2016.pkl')\n",
    "_, _, scf_x, scf_y = lorenz_points(vals_distribution=scf_df['networth'], weights=scf_df['wgt'])\n",
    "traceSCF = go.Scatter(x = scf_x, y = scf_y, name='SCF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "traces = []\n",
    "models_metrics = metrics('SCF', scf_df['networth'], scf_df['wgt'])\n",
    "for version in versions:\n",
    "    version_params = get_param_values(version + '/params.py')\n",
    "    k_cross_df = pd.read_pickle(version + '/k_cross.pkl')\n",
    "    _, _, x1, y1 = lorenz_points(vals_distribution= k_cross_df['k_cross'])\n",
    "    models_metrics = pd.merge(models_metrics, metrics(name= version.split(\"/\")[-1], income=k_cross_df['k_cross']), on=['percent','var'])\n",
    "    trace_experiment = go.Scatter(x = x1, y = y1, name=version[-15:])\n",
    "    traces.append(trace_experiment)\n",
    "    #print(j, version.split(\"/\")[-1])\n",
    "    #print(version_params)\n",
    "    j += 1\n",
    "traces.append(traceSCF)\n",
    "fig= go.Figure(data=traces)\n",
    "#iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = ['percent', 'v1.0x1.0x1.0', 'v0.5x1.0x1.0', 'v1.0x1.0x2.0', 'v1.0x1.0x5.0', 'v0.5x1.0x5.0', 'SCF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent</th>\n",
       "      <th>v1.0x1.0x1.0</th>\n",
       "      <th>v0.5x1.0x1.0</th>\n",
       "      <th>v1.0x1.0x2.0</th>\n",
       "      <th>v1.0x1.0x5.0</th>\n",
       "      <th>v0.5x1.0x5.0</th>\n",
       "      <th>SCF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.189140</td>\n",
       "      <td>0.188292</td>\n",
       "      <td>0.209566</td>\n",
       "      <td>0.246724</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.385638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.456906</td>\n",
       "      <td>0.464174</td>\n",
       "      <td>0.470590</td>\n",
       "      <td>0.493371</td>\n",
       "      <td>0.504236</td>\n",
       "      <td>0.651065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.629970</td>\n",
       "      <td>0.642570</td>\n",
       "      <td>0.632990</td>\n",
       "      <td>0.628756</td>\n",
       "      <td>0.644122</td>\n",
       "      <td>0.770603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.825739</td>\n",
       "      <td>0.842956</td>\n",
       "      <td>0.819681</td>\n",
       "      <td>0.794897</td>\n",
       "      <td>0.814410</td>\n",
       "      <td>0.882912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.924773</td>\n",
       "      <td>0.942842</td>\n",
       "      <td>0.917094</td>\n",
       "      <td>0.891921</td>\n",
       "      <td>0.912558</td>\n",
       "      <td>0.937322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.967893</td>\n",
       "      <td>0.985290</td>\n",
       "      <td>0.962451</td>\n",
       "      <td>0.945474</td>\n",
       "      <td>0.965941</td>\n",
       "      <td>0.969336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.989930</td>\n",
       "      <td>1.006063</td>\n",
       "      <td>0.987965</td>\n",
       "      <td>0.982318</td>\n",
       "      <td>1.001542</td>\n",
       "      <td>0.998622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.010070</td>\n",
       "      <td>-0.006063</td>\n",
       "      <td>0.012035</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>-0.001542</td>\n",
       "      <td>0.001378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>-0.006147</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>-0.005389</td>\n",
       "      <td>-0.004825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.001683</td>\n",
       "      <td>-0.004181</td>\n",
       "      <td>-0.001471</td>\n",
       "      <td>-0.000785</td>\n",
       "      <td>-0.004092</td>\n",
       "      <td>-0.005029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.789517</td>\n",
       "      <td>0.813796</td>\n",
       "      <td>0.786825</td>\n",
       "      <td>0.772529</td>\n",
       "      <td>0.801633</td>\n",
       "      <td>0.859581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    percent  v1.0x1.0x1.0  v0.5x1.0x1.0  v1.0x1.0x2.0  v1.0x1.0x5.0  \\\n",
       "0      0.01      0.189140      0.188292      0.209566      0.246724   \n",
       "1      0.05      0.456906      0.464174      0.470590      0.493371   \n",
       "2      0.10      0.629970      0.642570      0.632990      0.628756   \n",
       "3      0.20      0.825739      0.842956      0.819681      0.794897   \n",
       "4      0.30      0.924773      0.942842      0.917094      0.891921   \n",
       "5      0.40      0.967893      0.985290      0.962451      0.945474   \n",
       "6      0.60      0.989930      1.006063      0.987965      0.982318   \n",
       "7      0.40      0.010070     -0.006063      0.012035      0.017682   \n",
       "8      0.20      0.000878     -0.006147      0.001513      0.003333   \n",
       "9      0.10     -0.001683     -0.004181     -0.001471     -0.000785   \n",
       "10     0.00      0.789517      0.813796      0.786825      0.772529   \n",
       "\n",
       "    v0.5x1.0x5.0       SCF  \n",
       "0       0.249997  0.385638  \n",
       "1       0.504236  0.651065  \n",
       "2       0.644122  0.770603  \n",
       "3       0.814410  0.882912  \n",
       "4       0.912558  0.937322  \n",
       "5       0.965941  0.969336  \n",
       "6       1.001542  0.998622  \n",
       "7      -0.001542  0.001378  \n",
       "8      -0.005389 -0.004825  \n",
       "9      -0.004092 -0.005029  \n",
       "10      0.801633  0.859581  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_metrics_display = models_metrics.copy()\n",
    "models_metrics_display[columns_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_metrics_tab = models_metrics.copy()\n",
    "models_metrics_tab = models_metrics_tab[columns_list]\n",
    "for col in models_metrics_tab.columns[1:]:\n",
    "    models_metrics_tab[col] = models_metrics_tab[col].apply(lambda x: ' & ' + str(round(x*100, 1)))\n",
    "models_metrics_tab[models_metrics_tab.columns[-1]] = models_metrics_tab[models_metrics_tab.columns[-1]].apply(lambda x: x +'\\\\')\n",
    "models_metrics_tab[models_metrics_tab.columns[-1]] = models_metrics_tab[models_metrics_tab.columns[-1]].apply(lambda x: x +'\\\\')\n",
    "\n",
    "models_metrics_latex = models_metrics_tab[columns_list]\n",
    "lines = models_metrics_latex.to_string(index=False)\n",
    "with open(\"/Users/mitya/Desktop/newfile.txt\", 'w') as f:\n",
    "    for line in lines:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_aux_transform(x):\n",
    "    return np.sign(x)*np.log(np.abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c113e3a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "versionZ = '/Users/mitya/Desktop/inequality/codes/gitcode/inequality/output/'\n",
    "k_cross_df = pd.read_pickle(versionZ + '/k_cross_types.pkl')\n",
    "k_crossL = log_aux_transform(k_cross_df[k_cross_df['name']=='k_crossL']['values'].values)\n",
    "k_crossM = log_aux_transform(k_cross_df[k_cross_df['name']=='k_crossM']['values'].values)\n",
    "k_crossH = log_aux_transform(k_cross_df[k_cross_df['name']=='k_crossH']['values'].values)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "ax.hist(k_crossL, label='L', bins=50)\n",
    "ax.hist(k_crossM, label='M', bins=50)\n",
    "ax.hist(k_crossH, label='H', bins=50)\n",
    "ax.set_xlabel('Wealth')\n",
    "ax.set_ylabel('Population')\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_folder = '/Users/mitya/Desktop/inequality/codes/gitcode/inequality/output/'\n",
    "path = wd_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_immediate_subdirectories(wd_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_to_read = \"v20190125173347\"\n",
    "params_file_sel = wd_folder + v_to_read + '/params.py'\n",
    "with open(params_file_sel) as fp:\n",
    "        for cnt, line in enumerate(fp):\n",
    "            print (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = [wd_folder + v for v in get_immediate_subdirectories(wd_folder)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pure KS\n",
    "versions = ['v20190126111549', 'v20190126115709', 'v20190126143849', 'v20190126131131', 'v20190126170327']\n",
    "# KS-style\n",
    "#versions = ['v20190125142528', 'v20190125131930', 'v20190125164347', 'v20190126173919', 'v20190126184046', 'v20190126221526', 'v20190127001534']\n",
    "#pure Caroll\n",
    "versions = ['v20190120211417', 'v20190125173347', 'v20190120223143', 'v20190126164134']\n",
    "versions = ['v1.0x1.0x1.0', 'v0.5x1x2.0']\n",
    "versions = [wd_folder + v for v in versions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "traces = []\n",
    "for version in versions:\n",
    "    version_params = get_param_values(version + '/params.py')\n",
    "    k_cross_df = pd.read_pickle(version + '/k_cross.pkl')\n",
    "    _, _, x1, y1 = lorenz_points(vals_distribution= k_cross_df['k_cross'])\n",
    "    models_metrics = pd.merge(models_metrics, metrics(name= version.split(\"/\")[-1], income=k_cross_df['k_cross']), on=['percent','var'])\n",
    "    trace_experiment = go.Scatter(x = x1, y = y1, name=version[-15:])\n",
    "    traces.append(trace_experiment)\n",
    "    print(j, version.split(\"/\")[-1])\n",
    "    print(version_params)\n",
    "    j += 1\n",
    "traces.append(traceSCF)\n",
    "fig= go.Figure(data=traces)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_metrics = models_metrics.drop('var', axis= 1)\n",
    "for col in models_metrics.columns[1:]:\n",
    "    models_metrics[col] = models_metrics[col].apply(lambda x: ' & ' + str(round(x*100, 1)))\n",
    "models_metrics[models_metrics.columns[-1]] = models_metrics[models_metrics.columns[-1]].apply(lambda x: x +'\\\\')\n",
    "models_metrics[models_metrics.columns[-1]] = models_metrics[models_metrics.columns[-1]].apply(lambda x: x +'\\\\')\n",
    "\n",
    "lines = models_metrics.to_string(index=False)\n",
    "with open(\"/Users/mitya/Desktop/newfile.txt\", 'w') as f:\n",
    "    for line in lines:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df = pd.read_pickle('/Users/mitya/Desktop/inequality/codes/gitcode/inequality/data/scf2016.pkl')\n",
    "traceSCF = go.Scatter(x = scf_x, y = scf_y, name='SCF')\n",
    "\n",
    "_, _, scf_x, scf_y = lorenz_points(vals_distribution=scf_df['networth'], weights=scf_df['wgt'])\n",
    "#basic_model_df = pd.read_pickle('/Users/mitya/Desktop/inequality/codes/gitcode/inequality/temp/basic_model_lorenz.pkl')\n",
    "#basic_x0, basic_y0 = basic_model_df['basic_x0'], basic_model_df['basic_y0']\n",
    "\n",
    "#hetero0_df = pd.read_pickle('/Users/mitya/Desktop/inequality/codes/gitcode/inequality/output/KS_hetero_eqShF/k_cross.pkl')\n",
    "#x0, y0 = lorenz_points(vals_distribution= hetero0_df['k_cross'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mitya/Downloads/scf16.csv')\n",
    "pd.to_pickle(df, '/Users/mitya/Desktop/inequality/codes/gitcode/inequality/data/scf2016.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceSCF = go.Scatter(x = scf_x, y = scf_y, name='SCF')\n",
    "traceBasic = go.Scatter(x = basic_x0, y = basic_y0, name='Homo')\n",
    "#traceHetero0 = go.Scatter(x = x0, y = y0, name='Hetero0')\n",
    "#traceHetero1 = go.Scatter(x = x1, y = y1, name='Hetero1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(income, weights=None):\n",
    "    \n",
    "    if weights is None:\n",
    "        weights = np.ones(len(income))*1/len(income)\n",
    "\n",
    "    df = pd.DataFrame({'income': income, 'weights': weights}).sort_values('income', ascending= True)\n",
    "    \n",
    "    x = df['income']\n",
    "    f_x = df['weights'] / df['weights'].sum()\n",
    "    F_x = f_x.cumsum()\n",
    "    mu = np.sum(x * f_x)\n",
    "    cov = np.cov(x, F_x, rowvar=False, aweights=f_x)[0,1]\n",
    "    g = 2 * cov / mu\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version00 = \"/Users/mitya/Desktop/inequality/codes/gitcode/inequality/output/v20190126111549\"\n",
    "version01 = \"/Users/mitya/Desktop/inequality/codes/gitcode/inequality/output/v20190126115709\"\n",
    "\n",
    "version10 = \"/Users/mitya/Desktop/inequality/codes/gitcode/inequality/loop/v1.0x1.0x1.0\"\n",
    "version11 = \"/Users/mitya/Desktop/inequality/codes/gitcode/inequality/loop/v0.5x1x2.0\"\n",
    "\n",
    "version20 = \"/Users/mitya/Desktop/inequality/codes/gitcode/inequality/loop0/v20190120211417\"\n",
    "version21 = \"/Users/mitya/Desktop/inequality/codes/gitcode/inequality/loop0/v20190125173347\"\n",
    "\n",
    "version30 = \"/Users/mitya/Desktop/inequality/codes/gitcode/inequality/output/v1.0x1.0x1.0\"\n",
    "version31 = \"/Users/mitya/Desktop/inequality/codes/gitcode/inequality/output/v0.5x1.0x2.0\"\n",
    "version32 = \"/Users/mitya/Desktop/inequality/codes/gitcode/inequality/output/v0.75x1.0x4.0\"\n",
    "\n",
    "\n",
    "\n",
    "k_cross_df = pd.read_pickle(version32 + '/k_cross.pkl')\n",
    "gini3(income= k_cross_df['k_cross'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, k = gini(income= scf_df['networth'], weights= scf_df['wgt'])\n",
    "k.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_SCF = []\n",
    "for i in ['10', '13', '16']:\n",
    "    scf_df = pd.read_pickle('/Users/mitya/Desktop/inequality/codes/gitcode/inequality/data/scf20' + i + '.pkl')\n",
    "    scf_x, scf_y = lorenz_points(vals_distribution=scf_df['networth'], weights=scf_df['wgt'])\n",
    "    traceSCF = go.Scatter(x = scf_x, y = scf_y, name='SCF')\n",
    "    traces_SCF.append(traceSCF)\n",
    "fig= go.Figure(data=traces_SCF)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_folder_out = wd_folder + 'output' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# define the name of the directory to be created\n",
    "path = wd_folder + \"year\"\n",
    "\n",
    "try:  \n",
    "    os.mkdir(path)\n",
    "except OSError:  \n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "else:  \n",
    "    print (\"Successfully created the directory %s \" % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_primeL = np.array(dfL.iloc[:, 0]).reshape((ngridk, ngridkm, nstates_ag, nstates_id))\n",
    "k_primeM = np.array(dfM.iloc[:, 0]).reshape((ngridk, ngridkm, nstates_ag, nstates_id))\n",
    "k_primeH = np.array(dfH.iloc[:, 0]).reshape((ngridk, ngridkm, nstates_ag, nstates_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "connection = MongoClient(\"ds211925-a0.mlab.com\", 11925)\n",
    "db = connection[\"heroku_19288g0l\"]\n",
    "db.authenticate(\"tomerbal\", \"sa8Txwsc\")\n",
    "collection = db['chargers']\n",
    "cursor = collection.find({}).limit(5)\n",
    "for document in cursor:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(collection.find().limit(5)))\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['charging', 'code', 'damaged', 'deliverable', 'distance', 'gps_at',\n",
    "       'id', 'label', 'lastGps', 'lastTrip', 'last_ride_ended_at', 'location',\n",
    "       'model', 'needs_test_ride']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_type = np.array(([0.995, 0.005, 0.0],\n",
    "                      [0.005, 0.99, 0.005],\n",
    "                      [0.0, 0.005, 0.995]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = qe.MarkovChain(prob_type)\n",
    "stat_dist = mc.stationary_distributions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_grid(k_min, k_max, n_points, tau=0):\n",
    "    if tau!=0:\n",
    "        x = np.linspace(0, 0.5, n_points)\n",
    "        y = (x/np.max(x))**tau\n",
    "        return k_min + (k_max-k_min)*y\n",
    "    else:\n",
    "        return np.linspace(k_min, k_max, n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate individual capital grid\n",
    "k = generate_grid(k_min, k_max, ngridk, tau)\n",
    "\n",
    "# generate aggregate grid\n",
    "km = generate_grid(km_min, km_max, ngridkm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from scipy.interpolate import RectBivariateSpline, interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = [int(i) for i in np.arange(0, 6/1.8)]\n",
    "k[[int(i) for i in np.arange(0, 6/1.8)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_primeH[int(i) for i in np.arange(0, 6/1.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for km_val in [0, 3, 6, 9]:\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "    for i in range(nstates_ag):\n",
    "        for j in range(nstates_id):\n",
    "\n",
    "            x_vals = k[0:120]\n",
    "            y_vals = RectBivariateSpline(k, km, k_primeH[:, :, i, j]).ev(x_vals, km[km_val])\n",
    "            ax[i, j].plot(x_vals, y_vals, label='Agg = %s, Emp = %s, Type = H' % (i,j))\n",
    "            ax[i, j].set_xlabel('')\n",
    "            ax[i, j].legend(loc='best', fontsize=8)\n",
    "\n",
    "            y_vals = RectBivariateSpline(k, km, k_primeM[:, :, i, j]).ev(x_vals, km[km_val])\n",
    "            ax[i, j].plot(x_vals, y_vals, label='Agg = %s, Emp = %s, Type = M' % (i,j))\n",
    "            ax[i, j].set_xlabel('')\n",
    "            ax[i, j].legend(loc='best', fontsize=8)\n",
    "\n",
    "            y_vals = RectBivariateSpline(k, km, k_primeL[:, :, i, j]).ev(x_vals, km[km_val])\n",
    "            ax[i, j].plot(x_vals, y_vals, label='Agg = %s, Emp = %s, Type = L' % (i,j))\n",
    "            ax[i, j].set_xlabel('')\n",
    "            ax[i, j].legend(loc='best', fontsize=8)\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type_array = [] \n",
    "for i in range(nstates_ag):\n",
    "    for j in range(nstates_id):\n",
    "        x_vals = k[0:80]\n",
    "        y_vals = RectBivariateSpline(k, km, k_primeH[:, :, i, j]).ev(x_vals, km[5])\n",
    "        trace = go.Scatter(x = x_vals, y = y_vals, name='H' + str(i) + \":\" + str(j))\n",
    "        type_array.append(trace)\n",
    "        y_vals = RectBivariateSpline(k, km, k_primeM[:, :, i, j]).ev(x_vals, km[5])\n",
    "        trace = go.Scatter(x = x_vals, y = y_vals, name='M' + str(i) + \":\" + str(j))\n",
    "        type_array.append(trace)\n",
    "fig= go.Figure(data=type_array)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_folder = '/Users/mitya/Desktop/inequality/codes/gitcode/inequality/'\n",
    "df = pd.read_pickle(wd_folder + 'temp/types_shocks.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 2\n",
    "aa = df.iloc[0: 1490, j]\n",
    "bb = df.iloc[1: 1491, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = []\n",
    "for j in range(1, 9000):\n",
    "    aa = df.iloc[0: 1490, j]\n",
    "    bb = df.iloc[1: 1491, j]\n",
    "    trans_df = pd.DataFrame({'tod': list(aa), 'tom': list(bb)}).dropna()\n",
    "    if trans_df[trans_df['tod']=='M'].shape[0]!=0:\n",
    "        ratio = trans_df[(trans_df['tod']=='M') & (trans_df['tom']=='L')].shape[0]/trans_df[trans_df['tod']=='M'].shape[0]\n",
    "        ratios.append(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.matmul(np.array([x2 - 1.5, 1.5 - x1]),np.array([[f11, f12], [f21, f22]]))\n",
    "k = np.matmul(n, np.array([[y2 - 3.3], [3.3 - y1]]))\n",
    "k/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = prob_a\n",
    "s = np.zeros(r)\n",
    "n_periods = 12\n",
    "n = 2\n",
    "s[s0] = 1\n",
    "state = []\n",
    "\n",
    "cum = np.matmul(T, np.triu(np.ones(T.shape)))\n",
    "\n",
    "for k in range(len(X)):\n",
    "    state.append(s.astype(int))\n",
    "    ppi = np.insert(arr=np.matmul(s.T, cum), obj=0, values=0)\n",
    "    s = (((X[k] <= ppi[1:r+1])*(X[k] > ppi[0:r])).T)\n",
    "\n",
    "start = n_periods - n \n",
    "state = np.vstack(state)\n",
    "chain = np.matmul(V, state.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(V, state.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.array([0,1,2,3,4,1,0,1,2,3,2,1,0,1,2,3,2,1,0,1,4,3,2,1,0])\n",
    "gini3(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini4(x , weight = None):\n",
    "    '''\n",
    "    gini(x, weight)\n",
    "    Calculates the index gini to an array or list given.\n",
    "    INPUTS:\n",
    "        x: It is an 1-D array of monetary variable.\n",
    "        weight: It is an 1-D array of wieghts of x\n",
    "    RETUNRS: The gini index of x\n",
    "    \n",
    "    '''\n",
    "    import scipy as sp\n",
    "\n",
    "    # weight case\n",
    "    \n",
    "    x, y = dist_lorentz(x)\n",
    "\n",
    "    B = sp.integrate.trapz(y, x)  # area under lorentz curve\n",
    "    AB = 0.5                              # area under bisetrix curve\n",
    "    A = AB - B                            # area between lorentz and bisetrix\n",
    "    res = A / AB                          # gini index\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_lorentz(x):\n",
    "    import numpy as np\n",
    "    \n",
    "    y = np.array(x)           # y-axis data\n",
    "    y = np.sort(y, kind='mergesort')\n",
    "\n",
    "    x = np.repeat(1, len(y))  # x-axis data\n",
    "\n",
    "    pct_x = x / sum(x)        # x normalized\n",
    "    pct_x = np.cumsum(pct_x)  # CDF x\n",
    "\n",
    "    pct_y = y / sum(y)        # y normalized\n",
    "    pct_y = np.cumsum(pct_y)  # CDF y\n",
    "\n",
    "    # starts with (0,0)\n",
    "\n",
    "    pct_y = np.insert(pct_y, 0, 0) \n",
    "    pct_x = np.insert(pct_x, 0, 0)\n",
    "\n",
    "    return pct_x, pct_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini4(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini3(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smin, smax, ns = -3.0, 10.0, 180\n",
    "beta = 0.90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_grid = np.linspace(start = smin, \n",
    "                    stop = smax, \n",
    "                    num = ns, \n",
    "                    endpoint= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_mat_vec, z_mat_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a_mat, z_mat] = np.meshgrid(a_vec, z_vec)\n",
    "a_mat_vec, z_mat_vec = a_mat.flatten(), z_mat.flatten()\n",
    "y_vec = a_mat_vec*z_mat_vec\n",
    "\n",
    "fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb://tomerbal:sa8Txwsc@ds211925-a0.mlab.com:11925,ds211925-a1.mlab.com:11925/heroku_19288g0l?replicaSet=rs-ds211925\")\n",
    "db = client.get_database(\"heroku_19288g0l\")\n",
    "collection = db['chargers']\n",
    "cursor = collection.find({})\n",
    "for document in cursor:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import Connection\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "client = MongoClient(\"mongodb://tomerbal:sa8Txwsc@ds211925-a0.mlab.com:11925\", authMechanism='SCRAM-SHA-1')\n",
    "db = client['heroku_19288g0l']\n",
    "for record in db.chargers.find().limit(10):\n",
    "     pprint.pprint(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in db.chargers.find().limit(10):\n",
    "     pprint.pprint(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_vec = np.array([0.80, 1.20])\n",
    "prob_z = np.array([[0.90, 0.100], [.10, 0.90]])\n",
    "\n",
    "a_vec =  np.array([ 0.95, 1.05 ])\n",
    "prob_a = np.array([[0.90, 0.10], [0.10, 0.90]])\n",
    "\n",
    "\n",
    "\n",
    "[a_mat, z_mat] = np.meshgrid(a_vec, z_vec)\n",
    "a_mat_vec, z_mat_vec = a_mat.flatten(), z_mat.flatten()\n",
    "y_vec = a_mat_vec*z_mat_vec\n",
    "\n",
    "na, nz, ny = a_vec.shape[0], z_vec.shape[0], y_vec.shape[0]\n",
    "\n",
    "#check dimensions of the matrices\n",
    "if(na*nz!=ny):\n",
    "    print(\"Something is wrong with the dimensions of the initial matrices.\")\n",
    "else:\n",
    "    prob_kron_za = np.kron(prob_z,prob_a)\n",
    "    prob_kron_za_3d = np.dstack([prob_kron_za]*ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.33\n",
    "deltaK = 0.10\n",
    "A = 1\n",
    "b_coeffs = [0.0732, 0.9695, 0.9455]\n",
    "# to initiate K grid, calculate K_ss, steady state value, and multiply by \n",
    "# the shares below to form a grid\n",
    "minK_share_init, maxK_share_init, nK = 0.5, 2.0, 3\n",
    "\n",
    "# min consumption allowed\n",
    "c_min = .01e-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c = np.ones([1, ns])\n",
    "V = np.ones([nK, ny, ns])/ (1 - beta)\n",
    "\n",
    "b_coeffs = np.array(b_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K_ss = (alpha /(1/beta - 1 + deltaK))**(1 /(1 - alpha))\n",
    "W_ss = A*(1 - alpha)*(alpha*A/(1/beta - 1 + deltaK))**(alpha /(1 - alpha))\n",
    "\n",
    "K_vec = np.linspace(start=minK_share_init*K_ss, \n",
    "                    stop=maxK_share_init*K_ss, \n",
    "                    num=nK, \n",
    "                    endpoint=True)\n",
    "\n",
    "K_mat = np.tile(K_vec,(ny,1)).T\n",
    "AK_mat = np.tile(a_mat_vec,(nK,1))\n",
    "\n",
    "\n",
    "K_mat_prime = b_coeffs[0]+b_coeffs[1]*np.log(AK_mat)+b_coeffs[2]*K_mat\n",
    "\n",
    "R_mat = 1 - deltaK + alpha*AK_mat/K_mat**(1 - alpha)\n",
    "R_mat_3d = np.dstack([R_mat]*ns)\n",
    "\n",
    "W_mat = (1 - alpha)*AK_mat*K_mat**alpha\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration, diff_V, max_iteration_num, min_diff_V   = 0, 1, 200, 1e-6\n",
    "EV = V\n",
    "sprime = s_grid \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AK_mat/K_mat**(1 - alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vinterp = []\n",
    "for iy in range (ny):\n",
    "\n",
    "    Vinterp_i = interpolate.interp1d(K_mat[:, iy], V[:, iy, :].T, fill_value='extrapolate', kind='linear')(K_mat_prime[:, iy])\n",
    "    Vinterp.append(Vinterp_i)\n",
    "\n",
    "Vinterp_swap = np.swapaxes(np.array(Vinterp), 1, 2)\n",
    "EV_swap = np.swapaxes(EV, 0, 1)\n",
    "\n",
    "EV_swap = np.einsum('mnr,ndr->mdr', prob_kron_za_3d,Vinterp_swap)\n",
    "EV = np.swapaxes(EV_swap, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while ((iteration <= max_iteration_num) & (diff_V > min_diff_V)):\n",
    "    \n",
    "    Vinterp = []\n",
    "    for iy in range (ny):\n",
    "        \n",
    "        Vinterp_i = interpolate.interp1d(K_mat[:, iy], V[:, iy, :].T, fill_value='extrapolate', kind='linear')(K_mat_prime[:, iy])\n",
    "        Vinterp.append(Vinterp_i)\n",
    "        \n",
    "    Vinterp_swap = np.swapaxes(np.array(Vinterp), 1, 2)\n",
    "    EV_swap = np.swapaxes(EV, 0, 1)\n",
    "    \n",
    "    EV_swap = np.einsum('mnr,ndr->mdr', prob_kron_za_3d,Vinterp_swap)\n",
    "    EV = np.swapaxes(EV_swap, 0, 1)\n",
    "    \n",
    "    zw_mat_3d = np.dstack([z_mat_vec*W_mat]*ns) \n",
    "    zw_sprime_grid = np.asarray([zw_mat_3d - sprime]*ns)\n",
    "    \n",
    "    \n",
    "    rs_mat_3d = np.multiply(R_mat_3d,s_grid)\n",
    "    rs_grid = np.swapaxes(np.asarray([rs_mat_3d]*ns), 3, 0)\n",
    "    \n",
    "    #4-dim array [s, _, _, sprime]\n",
    "    c = zw_sprime_grid + rs_grid\n",
    "    c_adj = np.where(c < c_min, c_min, c)\n",
    "    \n",
    "    v = np.log(c_adj) + np.asarray([beta*EV]*ns)\n",
    "    \n",
    "    max_ind, new_V = np.argmax(v, axis=3), np.moveaxis(np.max(v, axis=3), 0, -1)\n",
    "    \n",
    "    diff_V = np.max(np.abs(np.divide(new_V - V, new_V)))\n",
    "    V = new_V.copy()\n",
    "    \n",
    "    print (iteration, \":\", diff_V, end=\", \")    \n",
    "    iteration += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full grid of saving decisions: given s, iK and iy\n",
    "# the grid returns sprime, savings\n",
    "s_decisions = s_grid[max_ind]\n",
    "s_decisions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_mc (T, n, seed_param=123, drop1K=True, s0=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Simulates a Markov chain of length n for a given transition matrix T.\n",
    "    It outputs a chain of states.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed_param)\n",
    "    \n",
    "    n_periods = n\n",
    "    if (drop1K==True):\n",
    "        n_periods = n + 1001\n",
    "    \n",
    "    r, c = T.shape\n",
    "    V = np.arange(1, r+1)\n",
    "    \n",
    "    X = np.random.uniform(low=0, high=1, size=n_periods)\n",
    "\n",
    "    \n",
    "    s = np.zeros(r)\n",
    "    s[s0] = 1\n",
    "    state = []\n",
    "    \n",
    "    cum = np.matmul(T, np.triu(np.ones(T.shape)))\n",
    "    \n",
    "    for k in range(len(X)):\n",
    "        state.append(s.astype(int))\n",
    "        ppi = np.insert(arr=np.matmul(s.T, cum), obj=0, values=0)\n",
    "        s = (((X[k] <= ppi[1:r+1])*(X[k] > ppi[0:r])).T)\n",
    "    \n",
    "    start = n_periods - n \n",
    "    state = np.vstack(state)\n",
    "    chain = np.matmul(V, state.T)\n",
    "    \n",
    "    return chain[start:], state[start:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_individuals = 10\n",
    "time_periods = 15\n",
    "time_periods_drop = 1\n",
    "\n",
    "wnb = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def seed_gen(i):\n",
    "    \n",
    "    \"\"\"\n",
    "    outputs seed to simulate differen MC, randomization due to\n",
    "    execution time and invidual id (counting number)\n",
    "    \"\"\"\n",
    "    \n",
    "    time_float = time.time()\n",
    "    time_with_increment = time.time() + i\n",
    "    int_part, dec_part = divmod(time_with_increment, 1)\n",
    "    num = divmod(int_part, 10000)[1]*10000 + int(dec_part*10000)\n",
    "    \n",
    "    return int(num) + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mcs_individuals = []\n",
    "\n",
    "for k in range(num_individuals):\n",
    "    ind_seed = seed_gen(k)\n",
    "    ind_mc, _ = simulate_mc(prob_z, time_periods, ind_seed)\n",
    "    sim_mcs_individuals.append(ind_mc)\n",
    "    \n",
    "sim_mcs_individuals = np.array(sim_mcs_individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sim_mcs_aggregate, _ = simulate_mc(prob_a, time_periods, seed_gen(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "sA_pd = pd.read_csv(\"/Users/mitya/Downloads/inequality/codes/old stuff/krusell_smith1998_a/svngs_agg.csv\", sep=\",\", header=None)\n",
    "sZ_pd = pd.read_csv(\"/Users/mitya/Downloads/inequality/codes/old stuff/krusell_smith1998_a/svngs_ind.csv\", sep=\",\", header=None)\n",
    "\n",
    "sA, sZ = sA_pd.T.values, sZ_pd.values\n",
    "sim_mcs_aggregate, sim_mcs_individuals = np.squeeze(sA), sZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_overlap_checker (sim_mcs_individuals, threshold=0.8):\n",
    "    \n",
    "    \"\"\"\n",
    "    check if simulated MCs are not overlapping:\n",
    "    outputs printout of highly overlapped MCs only\n",
    "    \"\"\"\n",
    "    \n",
    "    num_individuals, _ = sim_mcs_individuals.shape\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(num_individuals):\n",
    "        for j in range(num_individuals):\n",
    "            avg = np.average(np.where(sim_mcs_individuals[i] == sim_mcs_individuals[j], 1, 0))\n",
    "        \n",
    "            if ((i!=j) & (avg > threshold)):\n",
    "                print (\"There is something wrong with the chains:\")\n",
    "                print (\"chain 1: \",i, \", chain 2: \", j, \", overlapping ratio: \", avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals_agg_chains = na*(sim_mcs_individuals - 1) + sim_mcs_aggregate - 1\n",
    "#individuals_agg_chains.shape\n",
    "\n",
    "# matrix of savings decisions for all individuals\n",
    "# for all periods, (s_grid, K_grid, number_of_individs, time_periods)\n",
    "s_dec_all_individs_periods = s_decisions[:,:,individuals_agg_chains]\n",
    "#s_dec_all_individs_periods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation_individ_period(dec_all_individs_periods, individ_num, period_num, params):\n",
    "    \n",
    "    # unpack parameters\n",
    "    K_vec, s_grid, sim_K, sim_s = \\\n",
    "    params['K_vec'], params['s_grid'], params['sim_K'], params['sim_s']\n",
    "    \n",
    "    interpolated_value = interpolate.interpn((K_vec, s_grid), \n",
    "                                             dec_all_individs_periods[:, :, individ_num, period_num].T, \n",
    "                                             [sim_K[0, period_num -1], sim_s[individ_num, period_num -1]], \n",
    "                                             method='linear')\n",
    "    \n",
    "    return max(min(interpolated_value[0],s_grid[-1]),s_grid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_s, sim_K = np.ones([num_individuals, time_periods])*K_ss, np.ones([1, time_periods])*K_ss\n",
    "params = {'K_vec': K_vec, 's_grid': s_grid, 'sim_K': sim_K, 'sim_s': sim_s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for tm_period in range(1,time_periods):\n",
    "    \n",
    "    # check if in-parallel will help\n",
    "    for ind_num in range(num_individuals):\n",
    "        \n",
    "        sim_s[ind_num, tm_period] = \\\n",
    "        interpolation_individ_period(s_dec_all_individs_periods, ind_num, tm_period, params)\n",
    "        \n",
    "    sim_K[0, tm_period] = np.average(sim_s[:, tm_period])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(sim_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KK_prime = sim_K[0,1:]\n",
    "\n",
    "AA = a_vec[sim_mcs_aggregate[1:] - 1]\n",
    "KK = sim_K[0,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KK_prime.shape, KK_prime[0:5], KK_prime[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.array([np.log(AA), KK]).T, KK_prime\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "reg_fit = sm.OLS(Y[time_periods_drop:], X[time_periods_drop:, :]).fit()\n",
    "b_coeffs_uptd = reg_fit.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_coeffs = wnb*b_coeffs_uptd + (1 - wnb)*b_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = reg_fit.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.append((b_coeffs, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array([np.insert(k[0], 0, k[1]) for k in b])).to_csv(\"/Users/mitya/Downloads/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
